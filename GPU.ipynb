{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb384ef-2cbb-4bde-87d6-3665d337f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pycaret\n",
    "# !pip install torch \n",
    "# !pip install torchvision\n",
    "# !pip install transformers \n",
    "# !pip install xgboost\n",
    "# !pip install catboost\n",
    "\n",
    "# ! pip install \\\n",
    "#     --extra-index-url=https://pypi.nvidia.com \\\n",
    "#     cudf-cu12==24.8.* dask-cudf-cu12==24.8.* cuml-cu12==24.8.* \\\n",
    "#     cugraph-cu12==24.8.* cuspatial-cu12==24.8.* cuproj-cu12==24.8.* \\\n",
    "#     cuxfilter-cu12==24.8.* cucim-cu12==24.8.* pylibraft-cu12==24.8.* \\\n",
    "#     raft-dask-cu12==24.8.* cuvs-cu12==24.8.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29184474-f4bb-4367-b4a9-373aa6084e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "%load_ext cudf.pandas\n",
    "%reload_ext cudf.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092d5137-00e9-4cab-93b1-1a324a43c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', None)  \n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image, ImageFile, UnidentifiedImageError\n",
    "import os\n",
    "import pycaret \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision \n",
    "from torchvision import datasets, models, transforms \n",
    "from tempfile import TemporaryDirectory \n",
    "from torch.utils.data import DataLoader \n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.models import resnet18, resnet50, VGG19_Weights\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  \n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import mlflow                                   \n",
    "# import mlflow.pytorch\n",
    "# Ignorer tous les avertissements\n",
    "# from torchmetrics.classification import Accuracy\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "# import numpy as np \n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# import pretrainedmodels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a239aefe-378d-492a-9a7b-be698c7aed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour voir l'utilisation de la memoire \n",
    "import psutil\n",
    "import os\n",
    "\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_info = process.memory_info()\n",
    "    return memory_info.rss  # Mémoire utilisée en bytes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7448aa9-ddad-414b-a806-61905b9bd8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4432ba2c-554a-4a94-9e2a-4fed05bd6402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'/root/Gohou/Data/Tabes/New_trans/df_global.csv'\n",
    "data = pd.read_csv('/root/Gohou/Data/Tabes/New_trans/df_global.csv')\n",
    "data = data.drop(['Unnamed: 0','Label', 'CODEBRAN'], axis =1)\n",
    "df = data.copy()\n",
    "\n",
    "# Gohou/Data/Tabes/New_trans/df_global .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db2fdc78-4447-4238-85f6-b5f08921975f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6618, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f4b9b3f-092c-4f82-a12d-1f068abdb685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130933 130933\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                                              </span>\n",
       "<span style=\"font-style: italic\">                                  Total time elapsed: 2.691 seconds                           </span>\n",
       "<span style=\"font-style: italic\">                                0 GPU function calls in 0.000 seconds                         </span>\n",
       "<span style=\"font-style: italic\">                                0 CPU function calls in 0.000 seconds                         </span>\n",
       "<span style=\"font-style: italic\">                                                                                              </span>\n",
       "<span style=\"font-style: italic\">                                                Stats                                         </span>\n",
       "<span style=\"font-style: italic\">                                                                                              </span>\n",
       "┏━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Function </span>┃<span style=\"font-weight: bold\"> GPU ncalls </span>┃<span style=\"font-weight: bold\"> GPU cumtime </span>┃<span style=\"font-weight: bold\"> GPU percall </span>┃<span style=\"font-weight: bold\"> CPU ncalls </span>┃<span style=\"font-weight: bold\"> CPU cumtime </span>┃<span style=\"font-weight: bold\"> CPU percall </span>┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "└──────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                                              \u001b[0m\n",
       "\u001b[3m                                  Total time elapsed: 2.691 seconds                           \u001b[0m\n",
       "\u001b[3m                                0 GPU function calls in 0.000 seconds                         \u001b[0m\n",
       "\u001b[3m                                0 CPU function calls in 0.000 seconds                         \u001b[0m\n",
       "\u001b[3m                                                                                              \u001b[0m\n",
       "\u001b[3m                                                Stats                                         \u001b[0m\n",
       "\u001b[3m                                                                                              \u001b[0m\n",
       "┏━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mFunction\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mGPU ncalls\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mGPU cumtime\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mGPU percall\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCPU ncalls\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCPU cumtime\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCPU percall\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "└──────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%cudf.pandas.profile\n",
    "\"\"\" Cette fonction nous permet d'avoir une liste des tous les chemins des images et une autres qui contient l'adressedes images dselon qu'elles soient stockées dans la base de donnees des images mais aussi dans la table fusionnée \"\"\"\n",
    "dossier = \"/root/Gohou/Data/images/photo_extracted/Photos_sinistres/photos\"\n",
    "import os \n",
    "def list_image_files(directory):\n",
    "    files = [] #le chemins complet    \n",
    "    adresse_images = [] #l'images elle meme     \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".jpeg\"):# Modifier selon les extensions d'images      \n",
    "            files.append(os.path.join(directory, filename))\n",
    "            adresse_images.append(filename)\n",
    "    return files, adresse_images \n",
    "chemins, images = list_image_files(dossier) \n",
    "print(len(chemins), len(images)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07d8e16d-2166-4b99-a624-35f90ff998da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Création des boîtes à moustaches pour chaque groupe\n",
    "# sns.boxplot(x='cluster', y= df['COUTS_SINISTRES'], data= df)\n",
    "\n",
    "# # Ajout de labels et titre\n",
    "# plt.title('Boîtes à Moustaches des Scores par Groupe')\n",
    "# plt.xlabel('Groupe')\n",
    "# plt.ylabel('Score')\n",
    "\n",
    "# # Affichage du graphique \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69f97a6e-03e1-420f-8806-2d47a3c6d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe_data(dataset, batch_size):\n",
    "    dfs = []\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        df = dataset.iloc[i:i + batch_size]\n",
    "        dfs.append(df) \n",
    "    return dfs\n",
    "dff = split_dataframe_data(df, 200)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71e2fd13-ae34-46d9-825d-fa3e2f9a704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa102251-7f4a-4b97-b7ba-1793489d1543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad72de-6a40-4208-b21e-3003cf55068c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before: 1026.14 MB\n"
     ]
    }
   ],
   "source": [
    "%%cudf.pandas.profile\n",
    "print(f\"Memory usage before: {get_memory_usage() / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "import gc\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def split_dataframe_into_batches(dataset, batch_size):\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        yield dataset.iloc[i:i + batch_size]\n",
    "\n",
    "def process_image(x):  \n",
    "    full_path = os.path.join(dossier, x) if isinstance(x, str) else x\n",
    "    if full_path in chemins and full_path not in treated_paths:\n",
    "        treated_paths.add(full_path) \n",
    "        try:\n",
    "            if os.path.exists(full_path):\n",
    "                with Image.open(full_path) as img:  # Use 'with' to ensure the image is closed after processing\n",
    "                    return img.copy()  # Return a copy to keep the image after the 'with' block\n",
    "            else:\n",
    "                print(f\"Image not found: {full_path}\")\n",
    "                return np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {full_path}: {e}\")\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan \n",
    "treated_paths = set() \n",
    "\n",
    "batch_df2 = pd.DataFrame() \n",
    "for batch_df in split_dataframe_into_batches(dff[21], 10):  # Adjust batch size if necessary\n",
    "    for i in range(1,5):\n",
    "        batch_df.loc[:,f'file_uploaded_photo_{i}'] = batch_df.loc[:,f'file_uploaded_photo_{i}'].apply(process_image)\n",
    "    batch_df2 = pd.concat([batch_df2, batch_df], ignore_index=True)\n",
    "    del batch_df \n",
    "    gc.collect()  \n",
    "\n",
    "print(f\"Memory usage after: {get_memory_usage() / (1024 * 1024):.2f} MB\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d5bc2-f7e2-46d9-9ae7-4692263cac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df2.dropna(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd2dd6-26a8-430f-adb6-c452b32ef004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79678fe0-2ef5-4041-81e6-824e5a82e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cudf.pandas.profile\n",
    "print(f\"Memory usage before: {get_memory_usage() / (1024 * 1024):.2f} MB\")\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "\n",
    "resnet_model = models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1')\n",
    "resnet_model.fc = nn.Identity()  # Remove the final classification layer\n",
    "\n",
    "image_transforms = transforms.Compose([ \n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])  \n",
    "\n",
    "def image_to_features(col): \n",
    "    image = image_transforms(col).unsqueeze(0)\n",
    "    features = resnet_model(image) \n",
    "    return features.squeeze(0) \n",
    "\n",
    "batch_df3 = pd.DataFrame() \n",
    "for batch_df in split_dataframe_into_batches(batch_df2, 10):  # Adjust batch size if necessary\n",
    "    for i in range(1,5):\n",
    "        batch_df.loc[:, f'feature_images_{i}'] = batch_df.loc[:,f'file_uploaded_photo_{i}'].apply(image_to_features) \n",
    "    batch_df3 = pd.concat([batch_df3, batch_df], ignore_index=True)\n",
    "    del batch_df \n",
    "    gc.collect()  \n",
    "print(f\"Memory usage after: {get_memory_usage() / (1024 * 1024):.2f} MB\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0acef2a-7b46-4941-9529-be5139218fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c448ca49-0cfa-4a30-93b4-9501e54b2398",
   "metadata": {},
   "source": [
    "### Bon avec CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf8add-9a4b-452c-93e7-aac2d57f4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cudf.pandas.profile\n",
    "# # import rmm\n",
    "# # rmm.reinitialize(pool_allocator=True, managed_memory=False)\n",
    "# print(f\"Memory usage before: {get_memory_usage() / (1024 * 1024):.2f} MB\")\n",
    "# import logging\n",
    "# from transformers import logging as transformers_logging\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "# import torch \n",
    "\n",
    "# # Configurer le niveau de logging pour ignorer les avertissements\n",
    "# transformers_logging.set_verbosity_error() \n",
    " \n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# bert_model = BertModel.from_pretrained('bert-base-uncased').to(device) \n",
    "# # bert_model = BertModel.from_pretrained(\"bert-base-uncased\", torch_dtype=torch.float16, attn_implementation=\"sdpa\")\n",
    "\n",
    "# def text_to_features(text): \n",
    "#     inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "#     outputs = bert_model(**inputs)\n",
    "#     return outputs.last_hidden_state.mean(dim=1).squeeze(0)  # squeeze(0) pour revoir la dimension\n",
    "\n",
    "# batch_df4 = pd.DataFrame() \n",
    "# for batch_df in split_dataframe_into_batches(batch_df3, 10):  # Adjust batch size if necessary\n",
    "#     batch_df.loc[:,'material_damage'] = batch_df.loc[:,'material_damage'].apply(text_to_features)\n",
    "#     batch_df.loc[:,'circonstance_detail'] = batch_df.loc[:,'circonstance_detail'].apply(text_to_features)\n",
    "#     batch_df.loc[:,'disaster_place'] = batch_df.loc[:,'disaster_place'].apply(text_to_features)\n",
    "#     batch_df4 = pd.concat([batch_df4, batch_df], ignore_index=True)\n",
    "#     del batch_df \n",
    "#     gc.collect()  \n",
    "# print(f\"Memory usage after: {get_memory_usage() / (1024 * 1024):.2f} MB\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac37a2c-e9a2-4ffc-aa90-5d058fb7196f",
   "metadata": {},
   "source": [
    "### BON sur GPU mais avec le modele de BERT ( Embbeding de dimension 768) plus de caracteristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d7b9e4-0344-4e2f-8ec9-7fd2b1c5e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cudf.pandas.profile\n",
    "# # import rmm\n",
    "# # rmm.reinitialize(pool_allocator=True, managed_memory=False)\n",
    "\n",
    "# print(f\"Memory usage before: {get_memory_usage() / (1024 * 1024):.2f} MB\")\n",
    "# import logging\n",
    "# from transformers import logging as transformers_logging\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "# import gc\n",
    "\n",
    "# # Configurer le niveau de logging pour ignorer les avertissements\n",
    "# transformers_logging.set_verbosity_error()\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "# def text_to_features(text):\n",
    "#     inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "#     inputs = {key: val.to(device) for key, val in inputs.items()}  # Déplacez les tenseurs sur le GPU\n",
    "#     outputs = bert_model(**inputs)\n",
    "#     return outputs.last_hidden_state.mean(dim=1).squeeze(0)  # Retourne le tenseur de caractéristiques\n",
    "\n",
    "\n",
    "# batch_df4 = pd.DataFrame() \n",
    "# for batch_df in split_dataframe_into_batches(batch_df3, 10):  # Adjust batch size if necessary\n",
    "#     batch_df['material_damage'] = batch_df['material_damage'].apply(text_to_features)\n",
    "#     batch_df['circonstance_detail'] = batch_df['circonstance_detail'].apply(text_to_features)\n",
    "#     batch_df['disaster_place'] = batch_df['disaster_place'].apply(text_to_features)\n",
    "#     batch_df4 = pd.concat([batch_df4, batch_df], ignore_index=True)\n",
    "#     del batch_df \n",
    "#     gc.collect()  \n",
    "# print(f\"Memory usage after: {get_memory_usage() / (1024 * 1024):.2f} MB\") \n",
    "\n",
    "\n",
    "# # batch_df4 = pd.DataFrame()\n",
    "# # for batch_df in split_dataframe_into_batches(batch_df3, 10):  # Ajustez la taille du lot si nécessaire\n",
    "# #     for column in ['material_damage', 'circonstance_detail', 'disaster_place']:\n",
    "# #         batch_df.loc[:, column] = batch_df[column].apply(text_to_features)\n",
    "# #     batch_df4 = pd.concat([batch_df4, batch_df], ignore_index=True)\n",
    "# #     del batch_df \n",
    "# #     gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96f136a-4500-410f-9c5a-8d80585c51f6",
   "metadata": {},
   "source": [
    "### BON sur GPU mais avec le modele de MiniLM ( Embbeding de dimension 386) plus de caracteristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bfb60a-04e6-472f-bf09-e2772a68cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cudf.pandas.profile\n",
    "# import rmm\n",
    "# rmm.reinitialize(pool_allocator=True, managed_memory=False)\n",
    "\n",
    "print(f\"Memory usage before: {get_memory_usage() / (1024 * 1024):.2f} MB\")\n",
    "import logging\n",
    "from transformers import logging as transformers_logging\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# Configurer le niveau de logging pour ignorer les avertissements\n",
    "transformers_logging.set_verbosity_error()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Chargement du modèle MiniLM\n",
    "model_name = \"microsoft/MiniLM-L12-H384-uncased\"  # MiniLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "miniLM_model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "def text_to_features(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}  # Déplacez les tenseurs sur le GPU\n",
    "    outputs = miniLM_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze(0)  # Retourne le tenseur de caractéristiques\n",
    "\n",
    "\n",
    "batch_df4 = pd.DataFrame() \n",
    "for batch_df in split_dataframe_into_batches(batch_df3, 10):  # Ajustez la taille du lot si nécessaire\n",
    "    batch_df['material_damage'] = batch_df['material_damage'].apply(text_to_features)\n",
    "    batch_df['circonstance_detail'] = batch_df['circonstance_detail'].apply(text_to_features)\n",
    "    batch_df['disaster_place'] = batch_df['disaster_place'].apply(text_to_features)\n",
    "    batch_df4 = pd.concat([batch_df4, batch_df], ignore_index=True)\n",
    "    del batch_df \n",
    "    gc.collect()  \n",
    "\n",
    "print(f\"Memory usage after: {get_memory_usage() / (1024 * 1024):.2f} MB\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350432b-6ae5-41eb-9347-dbd1c41ce559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde0746-b4c4-4e1b-9ec2-e7b7b2fcb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que vous avez déjà extrait vos caractéristiques d'images et de textes\n",
    "# %%cudf.pandas.profile\n",
    "X_images_np_1 = np.array([feat.detach().numpy() for feat in batch_df4['feature_images_1']])  # Convertir en tableau NumPy\n",
    "X_images_np_2 = np.array([feat.detach().numpy() for feat in batch_df4['feature_images_2']])\n",
    "X_images_np_3 = np.array([feat.detach().numpy() for feat in batch_df4['feature_images_3']])\n",
    "X_images_np_4 = np.array([feat.detach().numpy() for feat in batch_df4['feature_images_4']])\n",
    "X_texts_np_1 = np.array([feat.detach().cpu().numpy() for feat in batch_df4['material_damage']])  # Convertir en tableau NumPy\n",
    "X_texts_np_2 = np.array([feat.detach().cpu().numpy() for feat in batch_df4['circonstance_detail']]) \n",
    "X_texts_np_3 = np.array([feat.detach().cpu().numpy() for feat in batch_df4['disaster_place']]) \n",
    "X_marq_np = batch_df4['MARQVEHI'].to_numpy()\n",
    "X_typevehi_np = batch_df4['TYPEVEHI'].to_numpy()\n",
    "X_puivehi_np = batch_df4['PUISVEHI'].to_numpy()\n",
    "X_nbreplace_np = batch_df4['NOMBPLAC'].to_numpy()\n",
    "X_codegara_np = batch_df4['CODEGARA'].to_numpy()\n",
    "X_codecat_np = batch_df4['CODECATE'].to_numpy()\n",
    "# X_codebran_np = batch_df4['CODEBRAN'].to_numpy()\n",
    "X_capri1_np = batch_df4['valeur_neuve'].to_numpy()\n",
    "X_capri2_np = batch_df4['valeur_venale'].to_numpy() \n",
    "# X_texts_np_1 = np.array([feat for feat in batch_df4['material_damage']])\n",
    "# Redimensionner les tableaux si nécessaire\n",
    "X_images_np_1 = X_images_np_1.reshape(len(X_images_np_1), -1) # Redimensionner en 2D si c'est actuellement 1D\n",
    "X_images_np_2 = X_images_np_2.reshape(len(X_images_np_2), -1)\n",
    "X_images_np_3 = X_images_np_3.reshape(len(X_images_np_3), -1)\n",
    "X_images_np_4 = X_images_np_4.reshape(len(X_images_np_4), -1)\n",
    "X_texts_np_1 = X_texts_np_1.reshape(len(X_texts_np_1), -1) # Redimensionner en 2D si c'est actuellement 1D\n",
    "X_texts_np_2 = X_texts_np_2.reshape(len(X_texts_np_2), -1)\n",
    "X_texts_np_3 = X_texts_np_3.reshape(len(X_texts_np_3), -1) \n",
    "X_marq_np = X_marq_np.reshape(len(X_marq_np), -1)  # Redimensionner en 2D si c'est actuellement 1D\n",
    "X_typevehi_np = X_typevehi_np.reshape(len(X_typevehi_np), -1)\n",
    "X_puivehi_np = X_puivehi_np.reshape(len(X_puivehi_np), -1)  # Redimensionner en 2D si c'est actuellement 1D\n",
    "X_nbreplace_np = X_nbreplace_np.reshape(len(X_nbreplace_np), -1)\n",
    "X_codegara_np = X_codegara_np.reshape(len(X_codegara_np), -1)  # Redimensionner en 2D si c'est actuellement 1D\n",
    "X_codecat_np = X_codecat_np.reshape(len(X_codecat_np), -1)\n",
    "# X_codebran_np = X_codebran_np.reshape(len(X_codebran_np), -1)\n",
    "X_capri1_np = X_capri1_np.reshape(len(X_capri1_np), -1)\n",
    "X_capri2_np = X_capri2_np.reshape(len(X_capri2_np), -1)\n",
    "\n",
    "# Concaténer ou combiner vos caractéristiques\n",
    "X_combined = np.concatenate((X_texts_np_1, X_texts_np_2, X_texts_np_3, X_images_np_1, X_images_np_2, X_images_np_3, X_images_np_4, X_marq_np, X_typevehi_np, X_puivehi_np, X_nbreplace_np, X_codegara_np, X_codecat_np, X_capri1_np, X_capri2_np), axis=1) #X_capri2_np,  X_texts_np_3, X_images_np_4, X_texts_np_2, ,X_images_np_3 \n",
    "\n",
    "# Labels ou cibles\n",
    "y = batch_df4['cluster'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006c1be-8437-4ed0-8716-2d9f6405048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = [f'feature_{i+1}' for i in range(X_combined.shape[1])]\n",
    "X1_combined = pd.DataFrame(X_combined, columns = columns_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b6c6ed-b63e-4077-9743-eff54d88dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9c9f4c-9fe0-4b1c-9eba-d138719bd21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([X1_combined, batch_df4[['id', 'CODEINTE_NUMEPOLI_CODERISQ', 'COUTS_SINISTRES', 'cluster']]], axis=1)\n",
    "df3.to_csv('/root/Gohou/Data/Tabes/New_trans/df21.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad76eee-d985-49f3-9f57-549791f0370a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b3228d-9ddf-42e5-b492-13799e399c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1630d-39a2-46a3-9da5-5d7116082c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18a392f-051b-49da-8b27-8e332faa5597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d3059-ae1d-4f2a-9987-d56392c66f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84f0654c-da8e-4d5a-894f-8569341a49b6",
   "metadata": {},
   "source": [
    "### ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a950d17-bd6f-4ab2-800c-cc54b6e1ee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "n_files = 34 # Remplace ceci par le nombre exact de fichiers CSV que tu as\n",
    "\n",
    "# Crée une liste des chemins des fichiers CSV\n",
    "file_paths = [f'/root/Gohou/Data/Tabes/New_trans/df{i}.csv' for i in range(n_files)]\n",
    "\n",
    "# Lire les fichiers CSV et stocker les DataFrames dans une liste\n",
    "list_df = [pd.read_csv(file_path) for file_path in file_paths] \n",
    "print(len(list_df))\n",
    "df_final = pd.concat(list_df, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e94c897d-98ce-4336-bfe8-c32bd11afff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_final.copy()\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbb90412-9901-4efd-8462-acbda9942e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance expliquée par chaque composante principale :  0.8001663613495702\n",
      "Nombre de composantes principales sélectionnées :  1084\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                                                              </span>\n",
       "<span style=\"font-style: italic\">                                         Total time elapsed: 150.377 seconds                                  </span>\n",
       "<span style=\"font-style: italic\">                                      12837 GPU function calls in 3.963 seconds                               </span>\n",
       "<span style=\"font-style: italic\">                                        5 CPU function calls in 0.059 seconds                                 </span>\n",
       "<span style=\"font-style: italic\">                                                                                                              </span>\n",
       "<span style=\"font-style: italic\">                                                        Stats                                                 </span>\n",
       "<span style=\"font-style: italic\">                                                                                                              </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Function                 </span>┃<span style=\"font-weight: bold\"> GPU ncalls </span>┃<span style=\"font-weight: bold\"> GPU cumtime </span>┃<span style=\"font-weight: bold\"> GPU percall </span>┃<span style=\"font-weight: bold\"> CPU ncalls </span>┃<span style=\"font-weight: bold\"> CPU cumtime </span>┃<span style=\"font-weight: bold\"> CPU percall </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "│ DataFrame.drop           │ 1          │ 0.972       │ 0.972       │ 0          │ 0.000       │ 0.000       │\n",
       "│ DataFrame                │ 2          │ 0.000       │ 0.000       │ 1          │ 0.001       │ 0.001       │\n",
       "│ Series.apply             │ 0          │ 0.000       │ 0.000       │ 2          │ 0.036       │ 0.018       │\n",
       "│ Series.any               │ 2          │ 0.040       │ 0.020       │ 0          │ 0.000       │ 0.000       │\n",
       "│ Series.__len__           │ 0          │ 0.000       │ 0.000       │ 2          │ 0.023       │ 0.011       │\n",
       "│ is_bool_dtype            │ 6416       │ 1.543       │ 0.000       │ 0          │ 0.000       │ 0.000       │\n",
       "│ is_extension_array_dtype │ 6416       │ 1.407       │ 0.000       │ 0          │ 0.000       │ 0.000       │\n",
       "└──────────────────────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                                                              \u001b[0m\n",
       "\u001b[3m                                         Total time elapsed: 150.377 seconds                                  \u001b[0m\n",
       "\u001b[3m                                      12837 GPU function calls in 3.963 seconds                               \u001b[0m\n",
       "\u001b[3m                                        5 CPU function calls in 0.059 seconds                                 \u001b[0m\n",
       "\u001b[3m                                                                                                              \u001b[0m\n",
       "\u001b[3m                                                        Stats                                                 \u001b[0m\n",
       "\u001b[3m                                                                                                              \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mFunction                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mGPU ncalls\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mGPU cumtime\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mGPU percall\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCPU ncalls\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCPU cumtime\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCPU percall\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "│ DataFrame.drop           │ 1          │ 0.972       │ 0.972       │ 0          │ 0.000       │ 0.000       │\n",
       "│ DataFrame                │ 2          │ 0.000       │ 0.000       │ 1          │ 0.001       │ 0.001       │\n",
       "│ Series.apply             │ 0          │ 0.000       │ 0.000       │ 2          │ 0.036       │ 0.018       │\n",
       "│ Series.any               │ 2          │ 0.040       │ 0.020       │ 0          │ 0.000       │ 0.000       │\n",
       "│ Series.__len__           │ 0          │ 0.000       │ 0.000       │ 2          │ 0.023       │ 0.011       │\n",
       "│ is_bool_dtype            │ 6416       │ 1.543       │ 0.000       │ 0          │ 0.000       │ 0.000       │\n",
       "│ is_extension_array_dtype │ 6416       │ 1.407       │ 0.000       │ 0          │ 0.000       │ 0.000       │\n",
       "└──────────────────────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Not all pandas operations ran on the GPU. The following functions required CPU fallback:\n",
       "\n",
       "- DataFrame\n",
       "- Series.apply\n",
       "- Series.__len__\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Not all pandas operations ran on the GPU. The following functions required CPU fallback:\n",
       "\n",
       "- DataFrame\n",
       "- Series.apply\n",
       "- Series.__len__\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">To request GPU support for any of these functions, please file a Github issue here: \n",
       "<a href=\"https://github.com/rapidsai/cudf/issues/new?assignees=&labels=%3F+-+Needs+Triage%2C+feature+request&projects=&template=pandas_function_request.md&title=%5BFEA%5D\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/rapidsai/cudf/issues/new/choose</span></a><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "To request GPU support for any of these functions, please file a Github issue here: \n",
       "\u001b]8;id=653306;https://github.com/rapidsai/cudf/issues/new?assignees=&labels=%3F+-+Needs+Triage%2C+feature+request&projects=&template=pandas_function_request.md&title=%5BFEA%5D\u001b\\\u001b[4;94mhttps://github.com/rapidsai/cudf/issues/new/choose\u001b[0m\u001b]8;;\u001b\\\u001b[4;94m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%cudf.pandas.profile\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop(columns=['Unnamed: 0', 'id', 'CODEINTE_NUMEPOLI_CODERISQ', 'COUTS_SINISTRES', 'cluster'], axis =1)  # Variables indépendantes\n",
    "# Étape 1 : Normalisation des données\n",
    "scaler = StandardScaler() \n",
    "X_scaled = scaler.fit_transform(X)  # Normaliser tes données (X est ton jeu de données)\n",
    "\n",
    "# Étape 2 : Application de l'ACP\n",
    "pca = PCA(n_components = 0.8)  # Conserver 95% de la variance expliquée\n",
    "X_pca = pca.fit_transform(X_scaled) \n",
    "\n",
    "# Afficher la variance expliquée par chaque composante principale\n",
    "print(\"Variance expliquée par chaque composante principale : \", sum(pca.explained_variance_ratio_))\n",
    "print(\"Nombre de composantes principales sélectionnées : \", pca.n_components_)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e19390-5563-4304-8708-614dbac2b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# X = df_final.drop(columns=['cluster','Unnamed: 0'])  # Variables indépendantes\n",
    "# # Étape 1 : Normalisation des données\n",
    "# scaler = StandardScaler() \n",
    "# X_scaled = scaler.fit_transform(X)  # Normaliser tes données (X est ton jeu de données)\n",
    "\n",
    "# # Étape 2 : Application de l'ACP\n",
    "# pca = PCA(n_components = 0.8)  # Conserver 95% de la variance expliquée\n",
    "# X_pca = pca.fit_transform(X_scaled) \n",
    "\n",
    "# # Afficher la variance expliquée par chaque composante principale\n",
    "# print(\"Variance expliquée par chaque composante principale : \", sum(pca.explained_variance_ratio_))\n",
    "# print(\"Nombre de composantes principales sélectionnées : \", pca.n_components_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "411dbc54-6dce-4685-9a6d-133151469f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Enregistrer le modèle\n",
    "with open('/root/Gohou/Data/Tabes/New_trans/ACP_SUP.pkl', 'wb') as acp:\n",
    "    pickle.dump(pca, acp)  \n",
    "\n",
    "with open('/root/Gohou/Data/Tabes/New_trans/scaler_SUP.pkl', 'wb') as scale:\n",
    "    pickle.dump(scaler, scale)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cbe677b-8f6e-4451-9c88-9e2d46583fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6497, 1085)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca_df = pd.DataFrame(X_pca, columns=[f\"PC{i+1}\" for i in range(X_pca.shape[1])])\n",
    "df1 = pd.concat([X_pca_df, df_final[['id', 'CODEINTE_NUMEPOLI_CODERISQ', 'COUTS_SINISTRES', 'cluster']]], axis=1) \n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e23876b8-3059-4547-88ea-53a3fe8da3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.to_csv('/root/Gohou/Data/Tabes/New_trans/Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e966db32-48a6-42d6-9ab3-3332b88f0ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# # Supposez que X et y sont vos données d'entrée et les labels\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Appliquer l'undersampling\n",
    "# undersampler = RandomUnderSampler(random_state=42)\n",
    "# X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# # Entraînez votre modèle avec les données undersamplées\n",
    "# model = RandomForestClassifier(random_state=42)\n",
    "# model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# # Faites des prédictions et évaluez le modèle\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df6acef3-8be1-4fe9-8347-abab1ce3235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des classes avant suréchantillonnage : Counter({0: 2556, 1: 1327, 2: 626, 3: 363})\n",
      "Distribution des classes après suréchantillonnage : Counter({1: 2556, 3: 2556, 0: 2556, 2: 2556})\n"
     ]
    }
   ],
   "source": [
    "df = df1.copy()\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "X = df.drop(columns='cluster')  # Variables indépendantes\n",
    "y = df['cluster'] \n",
    "\n",
    "# # Séparation des données en ensembles d'entraînement et de test\n",
    "X_train1, X_test1, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42,stratify=y)\n",
    "X_train, X_test = X_train1.drop(columns=['id', 'CODEINTE_NUMEPOLI_CODERISQ', 'COUTS_SINISTRES']),  X_test1.drop(columns=['id', 'CODEINTE_NUMEPOLI_CODERISQ', 'COUTS_SINISTRES'])\n",
    "\n",
    "# Application de SMOTE pour suréchantillonner la classe minoritaire\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Vérifier la distribution des classes après suréchantillonnage\n",
    "print(\"Distribution des classes avant suréchantillonnage :\", Counter(y_train))\n",
    "print(\"Distribution des classes après suréchantillonnage :\", Counter(y_train_resampled)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d040fb-c7df-43da-8f23-3881c707efa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfdb357-b12c-4e51-a903-ed7ccfedabd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065ba0e-3254-4318-bd6a-c7b9dee67b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# # Séparation des données en ensembles d'entraînement et de test\n",
    "X_train1, X_test1, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42 ,stratify=y)\n",
    "X_train, X_test = X_train1.drop(columns=['id', 'CODEINTE_NUMEPOLI_CODERISQ', 'COUTS_SINISTRES']),  X_test1.drop(columns=['id', 'CODEINTE_NUMEPOLI_CODERISQ', 'COUTS_SINISTRES'])\n",
    "\n",
    "\n",
    "# Appliquer l'undersampling\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Entraînez votre modèle avec les données undersamplées\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Faites des prédictions et évaluez le modèle\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred)) \n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100  # Convertir en pourcentages\n",
    "# Affichage de la matrice de confusion avec les pourcentages\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_percent, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix (in %)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9bfa15-a482-4b88-b6c6-7510575cb8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_series = pd.Series(y_pred, index=X_test1.index, name='y_pred')\n",
    "y_test_series = pd.Series(y_test, index=X_test1.index, name='y_test')\n",
    "a = pd.concat([X_test1[['id','CODEINTE_NUMEPOLI_CODERISQ','COUTS_SINISTRES']], y_test_series, y_pred_series], axis=1)\n",
    "a.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd740164-eb84-4a27-bad3-04af5c2406b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold,cross_val_predict, train_test_split,GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression,ElasticNet, Ridge, Lasso\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "431d5d56-57ba-4f57-ac03-7fde9e3eeadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = int(np.sqrt(len(X_train_resampled.columns))) \n",
    "dico = {\n",
    "    'logistic': LogisticRegression(),\n",
    "    'elastic': LogisticRegression(penalty=\"elasticnet\", solver=\"saga\"),  #met beaucoup de temps \n",
    "    'ridge': LogisticRegression(penalty=\"l2\"),\n",
    "    'lasso': LogisticRegression(penalty=\"l1\"),\n",
    "    'Arbre': DecisionTreeClassifier(),\n",
    "    'Random': RandomForestClassifier(), \n",
    "    'xgb': xgb.XGBClassifier(),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'Gradient_boosting': GradientBoostingClassifier(),\n",
    "    'adaboost_classifier': AdaBoostClassifier(),\n",
    "    'Bagging': BaggingClassifier(DecisionTreeClassifier(max_depth=7)), \n",
    "    'SVM': SVC(),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'lightgbm': LGBMClassifier(),  # Ajout de LightGBM\n",
    "    'catboost': CatBoostClassifier(verbose=0)  # Ajout de CatBoost\n",
    "}\n",
    "\n",
    "param = [ \n",
    "    {\"C\": [0.01], \"max_iter\": [10000]},\n",
    "    {\"C\": [0.01], \"l1_ratio\": [0.1, 0.5, 0.7], \"max_iter\": [10000]},\n",
    "    {\"C\": [0.01], \"solver\": [\"sag\", \"lbfgs\", \"liblinear\"], \"max_iter\": [10000]}, # C grand surapprentissage \n",
    "    {\"C\": [0.01], \"solver\": [\"liblinear\"], \"max_iter\": [10000]},\n",
    "    {\"max_depth\": [5, 10], \"min_samples_split\": [10, 15], \"min_samples_leaf\": [5, 7]},\n",
    "    {\"n_estimators\": [200,300], \"min_samples_leaf\": [3, 5], \"max_features\": [0.7, 0.8], \"max_depth\": [8, 10]},\n",
    "    {'colsample_bytree': [0.5, 0.7], \"n_estimators\": [50, 100], \"max_depth\": [2, 3], \"objective\": [\"multi:softmax\"], \"num_class\": [4], \"subsample\": [0.5, 0.6]}, \n",
    "    {'n_neighbors': [10, 15], \"algorithm\": [\"auto\",\"ball_tree\"]}, # k petit surapprentissage \n",
    "    {\"n_estimators\": [800, 1000], \"max_depth\": [3], \"learning_rate\": [0.01, 0.05], \"min_samples_split\": [10, 15], \"min_samples_leaf\": [5, 7], \"subsample\": [0.5, 0.6]},\n",
    "    {\"n_estimators\": [800, 1000], \"learning_rate\": [0.01, 0.05], \"algorithm\": [\"SAMME\", \"SAMME.R\"]},\n",
    "    {\"n_estimators\": [50], \"max_features\": [0.5, 0.6], \"max_samples\":[0.5, 0.6]},\n",
    "    {\"kernel\": ['linear', 'rbf'], \"C\": [0.1], \"gamma\": [\"scale\", \"auto\"]}, #C grand => surapprentisage\n",
    "    {\"solver\": [\"eigen\", \"lsqr\"], \"shrinkage\": [\"auto\"]}, \n",
    "    {\"reg_param\": [0.7, 0.9], \"tol\": [1e-2, 0.1]},\n",
    "    {\"n_estimators\": [1000, 800], \"learning_rate\": [0.01, 0.05], \"max_depth\": [2, 3], \"num_leaves\": [20, 30, 40], \"colsample_bytree\": [0.5, 0.6], \"force_row_wise\": [True], 'verbose': [-1]},\n",
    "    {\"iterations\": [1000, 800], \"depth\": [3], \"learning_rate\": [0.01, 0.05], \"l2_leaf_reg\": [7, 10]}\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce50082a-ce49-4fb1-a75a-795ae7e231ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(nom_model, dico, param, X_train_resampled, y_train_resampled, kf, out):\n",
    "    model = dico[nom_model]\n",
    "    model_cv = GridSearchCV(model, param_grid=param, cv=kf, scoring=\"f1_weighted\", error_score=\"raise\")  # Utiliser \"f1\" au lieu de \"f1_score\"\n",
    "    temps_debut = time.time() \n",
    "    model_cv.fit(X_train_resampled, y_train_resampled) \n",
    "    temps_fin = time.time()\n",
    "    # temps_execution = temps_fin - temps_debut\n",
    "    out[nom_model]={\"best_model\":model_cv.best_estimator_,\"meilleurs_parametres\":model_cv.best_params_, \"f1_score\": model_cv.best_score_,\"temps\":[time.ctime(temps_debut), time.ctime(temps_fin)]}\n",
    "    print(f'-----------------  Entrainement de {nom_model} est terminé  -----------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9140201-1122-42e1-a23f-40e68249fbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                                              </span>\n",
       "<span style=\"font-style: italic\">                                  Total time elapsed: 0.154 seconds                           </span>\n",
       "<span style=\"font-style: italic\">                                0 GPU function calls in 0.000 seconds                         </span>\n",
       "<span style=\"font-style: italic\">                                0 CPU function calls in 0.000 seconds                         </span>\n",
       "<span style=\"font-style: italic\">                                                                                              </span>\n",
       "<span style=\"font-style: italic\">                                                Stats                                         </span>\n",
       "<span style=\"font-style: italic\">                                                                                              </span>\n",
       "┏━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Function </span>┃<span style=\"font-weight: bold\"> GPU ncalls </span>┃<span style=\"font-weight: bold\"> GPU cumtime </span>┃<span style=\"font-weight: bold\"> GPU percall </span>┃<span style=\"font-weight: bold\"> CPU ncalls </span>┃<span style=\"font-weight: bold\"> CPU cumtime </span>┃<span style=\"font-weight: bold\"> CPU percall </span>┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "└──────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                                              \u001b[0m\n",
       "\u001b[3m                                  Total time elapsed: 0.154 seconds                           \u001b[0m\n",
       "\u001b[3m                                0 GPU function calls in 0.000 seconds                         \u001b[0m\n",
       "\u001b[3m                                0 CPU function calls in 0.000 seconds                         \u001b[0m\n",
       "\u001b[3m                                                                                              \u001b[0m\n",
       "\u001b[3m                                                Stats                                         \u001b[0m\n",
       "\u001b[3m                                                                                              \u001b[0m\n",
       "┏━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mFunction\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mGPU ncalls\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mGPU cumtime\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mGPU percall\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCPU ncalls\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCPU cumtime\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCPU percall\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "└──────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-20 (train_model):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_3835/99327755.py\", line 5, in train_model\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\", line 970, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\", line 1527, in _run_search\n",
      "    evaluate_candidates(ParameterGrid(self.param_grid))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\", line 916, in evaluate_candidates\n",
      "    out = parallel(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1863, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1792, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 2395, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 2275, in _prepare_train_params\n",
      "    train_pool = _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs, graph,\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 1513, in _build_train_pool\n",
      "    train_pool = Pool(X, y, cat_features=cat_features, text_features=text_features, embedding_features=embedding_features, pairs=pairs, graph=graph, weight=sample_weight, group_id=group_id,\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 855, in __init__\n",
      "    self._init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight,\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 1491, in _init\n",
      "    self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight,\n",
      "  File \"_catboost.pyx\", line 4339, in _catboost._PoolBase._init_pool\n",
      "  File \"_catboost.pyx\", line 4391, in _catboost._PoolBase._init_pool\n",
      "  File \"_catboost.pyx\", line 4200, in _catboost._PoolBase._init_features_order_layout_pool\n",
      "  File \"_catboost.pyx\", line 3096, in _catboost._set_features_order_data_pd_data_frame\n",
      "TypeError: Cannot convert ndarray to numpy.ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------  Entrainement de lasso est terminé  -----------------\n",
      "-----------------  Entrainement de logistic est terminé  -----------------\n",
      "-----------------  Entrainement de LDA est terminé  -----------------\n",
      "-----------------  Entrainement de ridge est terminé  -----------------\n",
      "-----------------  Entrainement de elastic est terminé  -----------------\n",
      "-----------------  Entrainement de QDA est terminé  -----------------\n",
      "-----------------  Entrainement de knn est terminé  -----------------\n",
      "-----------------  Entrainement de SVM est terminé  -----------------\n",
      "-----------------  Entrainement de Arbre est terminé  -----------------\n",
      "-----------------  Entrainement de xgb est terminé  -----------------\n",
      "-----------------  Entrainement de Bagging est terminé  -----------------\n"
     ]
    }
   ],
   "source": [
    "%%cudf.pandas.profile\n",
    "import threading\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "out = {}\n",
    "threads = []\n",
    "\n",
    "# Launch a thread for each model in the dictionary\n",
    "for i, nom_model in enumerate(dico):\n",
    "    param_v = param[i]\n",
    "    thread = threading.Thread(target=train_model, args=(nom_model, dico, param_v, X_train_resampled, y_train_resampled, kf, out))\n",
    "    threads.append(thread)\n",
    "    thread.start() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1165ef41-fb34-4e63-be4d-b03d4c405da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model</th>\n",
       "      <th>meilleurs_parametres</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>temps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000, pen...</td>\n",
       "      <td>{'C': 0.01, 'max_iter': 10000, 'solver': 'libl...</td>\n",
       "      <td>0.586748</td>\n",
       "      <td>[Thu Oct 24 13:34:45 2024, Thu Oct 24 14:06:35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000)</td>\n",
       "      <td>{'C': 0.01, 'max_iter': 10000}</td>\n",
       "      <td>0.711966</td>\n",
       "      <td>[Thu Oct 24 13:34:45 2024, Thu Oct 24 14:08:28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>LinearDiscriminantAnalysis(shrinkage='auto', s...</td>\n",
       "      <td>{'shrinkage': 'auto', 'solver': 'eigen'}</td>\n",
       "      <td>0.677255</td>\n",
       "      <td>[Thu Oct 24 13:34:45 2024, Thu Oct 24 14:28:13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000)</td>\n",
       "      <td>{'C': 0.01, 'max_iter': 10000, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.711966</td>\n",
       "      <td>[Thu Oct 24 13:34:45 2024, Thu Oct 24 14:49:47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elastic</th>\n",
       "      <td>LogisticRegression(C=0.01, l1_ratio=0.1, max_i...</td>\n",
       "      <td>{'C': 0.01, 'l1_ratio': 0.1, 'max_iter': 10000}</td>\n",
       "      <td>0.703424</td>\n",
       "      <td>[Thu Oct 24 13:34:45 2024, Thu Oct 24 14:58:15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>QuadraticDiscriminantAnalysis(reg_param=0.7, t...</td>\n",
       "      <td>{'reg_param': 0.7, 'tol': 0.01}</td>\n",
       "      <td>0.923993</td>\n",
       "      <td>[Thu Oct 24 13:34:45 2024, Thu Oct 24 15:01:43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>KNeighborsClassifier(n_neighbors=10)</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 10}</td>\n",
       "      <td>0.503680</td>\n",
       "      <td>[Thu Oct 24 13:34:45 2024, Thu Oct 24 15:07:44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>SVC(C=0.1, kernel='linear')</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "      <td>0.788589</td>\n",
       "      <td>[Thu Oct 24 13:34:45 2024, Thu Oct 24 15:19:51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbre</th>\n",
       "      <td>DecisionTreeClassifier(max_depth=10, min_sampl...</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 5, 'min_...</td>\n",
       "      <td>0.514351</td>\n",
       "      <td>[Thu Oct 24 13:34:45 2024, Thu Oct 24 15:23:00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'max_depth': 3, 'n_e...</td>\n",
       "      <td>0.811508</td>\n",
       "      <td>[Thu Oct 24 13:34:45 2024, Thu Oct 24 16:07:49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=7, random_st...</td>\n",
       "      <td>{'max_features': 0.5, 'max_samples': 0.6, 'n_e...</td>\n",
       "      <td>0.720944</td>\n",
       "      <td>[Thu Oct 24 13:34:45 2024, Thu Oct 24 16:25:04...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 best_model  \\\n",
       "lasso     LogisticRegression(C=0.01, max_iter=10000, pen...   \n",
       "logistic         LogisticRegression(C=0.01, max_iter=10000)   \n",
       "LDA       LinearDiscriminantAnalysis(shrinkage='auto', s...   \n",
       "ridge            LogisticRegression(C=0.01, max_iter=10000)   \n",
       "elastic   LogisticRegression(C=0.01, l1_ratio=0.1, max_i...   \n",
       "QDA       QuadraticDiscriminantAnalysis(reg_param=0.7, t...   \n",
       "knn                    KNeighborsClassifier(n_neighbors=10)   \n",
       "SVM                             SVC(C=0.1, kernel='linear')   \n",
       "Arbre     DecisionTreeClassifier(max_depth=10, min_sampl...   \n",
       "xgb       XGBClassifier(base_score=None, booster=None, c...   \n",
       "Bagging   (DecisionTreeClassifier(max_depth=7, random_st...   \n",
       "\n",
       "                                       meilleurs_parametres  f1_score  \\\n",
       "lasso     {'C': 0.01, 'max_iter': 10000, 'solver': 'libl...  0.586748   \n",
       "logistic                     {'C': 0.01, 'max_iter': 10000}  0.711966   \n",
       "LDA                {'shrinkage': 'auto', 'solver': 'eigen'}  0.677255   \n",
       "ridge     {'C': 0.01, 'max_iter': 10000, 'solver': 'lbfgs'}  0.711966   \n",
       "elastic     {'C': 0.01, 'l1_ratio': 0.1, 'max_iter': 10000}  0.703424   \n",
       "QDA                         {'reg_param': 0.7, 'tol': 0.01}  0.923993   \n",
       "knn                {'algorithm': 'auto', 'n_neighbors': 10}  0.503680   \n",
       "SVM        {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}  0.788589   \n",
       "Arbre     {'max_depth': 10, 'min_samples_leaf': 5, 'min_...  0.514351   \n",
       "xgb       {'colsample_bytree': 0.5, 'max_depth': 3, 'n_e...  0.811508   \n",
       "Bagging   {'max_features': 0.5, 'max_samples': 0.6, 'n_e...  0.720944   \n",
       "\n",
       "                                                      temps  \n",
       "lasso     [Thu Oct 24 13:34:45 2024, Thu Oct 24 14:06:35...  \n",
       "logistic  [Thu Oct 24 13:34:45 2024, Thu Oct 24 14:08:28...  \n",
       "LDA       [Thu Oct 24 13:34:45 2024, Thu Oct 24 14:28:13...  \n",
       "ridge     [Thu Oct 24 13:34:45 2024, Thu Oct 24 14:49:47...  \n",
       "elastic   [Thu Oct 24 13:34:45 2024, Thu Oct 24 14:58:15...  \n",
       "QDA       [Thu Oct 24 13:34:45 2024, Thu Oct 24 15:01:43...  \n",
       "knn       [Thu Oct 24 13:34:45 2024, Thu Oct 24 15:07:44...  \n",
       "SVM       [Thu Oct 24 13:34:45 2024, Thu Oct 24 15:19:51...  \n",
       "Arbre     [Thu Oct 24 13:34:45 2024, Thu Oct 24 15:23:00...  \n",
       "xgb       [Thu Oct 24 13:34:45 2024, Thu Oct 24 16:07:49...  \n",
       "Bagging   [Thu Oct 24 13:34:45 2024, Thu Oct 24 16:25:04...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1  = pd.DataFrame.from_dict(out, orient='index')\n",
    "out_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20586a21-31ba-4d8f-b813-6a9e6c83ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour s'assurer que tous les threads individuelles soient terminés avant que le thread principal prenne le relai. \n",
    "# On en pas besoin si on sait à quel moment tous nos threads vont tous se stopper \n",
    "\n",
    "for thread in threads:\n",
    "    thread.join() \n",
    "print(out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f42e85d7-14bb-4781-a8e2-632dba719afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9389331960668086\n"
     ]
    }
   ],
   "source": [
    "pred = out_1.loc[\"Bagging\",\"best_model\"].predict(X_train_resampled)\n",
    "f1_test = f1_score(y_train_resampled, pred, average='weighted')\n",
    "# X_train_resampled, y_train_resampled\n",
    "# f1_test = f1_score(y_train_resampled, pred, average='weighted')\n",
    "# f1_test = accuracy_score(y_test, pred)\n",
    "print(f1_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b22a3127-db64-4a99-8191-b586009e557e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.5, 'max_samples': 0.6, 'n_estimators': 80}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " out_1.loc[\"Bagging\",\"meilleurs_parametres\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7cf0e0-146d-4c33-8bb5-0a6776bebfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
